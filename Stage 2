# LSTM-based VaR Prediction Model

# Import libraries
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

# Data loading function
def load_data(file_path):
    # Load dataset
    data = pd.read_csv(file_path, delimiter=",")
    data['Date'] = pd.to_datetime(data['Date'])
    data['Return'] = data['Return'].astype(float)
    return data

# Preprocessing function
def preprocess_data(data, lookback=30):
    X, y = [], []
    for i in range(lookback, len(data)):
        X.append(data[i-lookback:i])
        y.append(data[i])
    return np.array(X), np.array(y)

# Define LSTM model
def build_lstm(input_shape):
    model = tf.keras.Sequential([
        tf.keras.layers.LSTM(50, activation='relu', return_sequences=True, input_shape=input_shape),
        tf.keras.layers.LSTM(50, activation='relu'),
        tf.keras.layers.Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse')
    return model

# Evaluate and visualize results
def evaluate_model(y_true, y_pred, dates):
    mse = mean_squared_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    print(f"MSE: {mse:.4f}, R2: {r2:.4f}")

    # Plot actual vs predicted
    plt.figure(figsize=(10, 6))
    plt.plot(dates, y_true, label='Actual')
    plt.plot(dates, y_pred, label='Predicted', linestyle='--')
    plt.legend()
    plt.title('Actual vs Predicted Returns')
    plt.xlabel('Date')
    plt.ylabel('Returns')
    plt.show()

# Backtesting VaR
def calculate_var(predictions, confidence_level=0.95):
    var_threshold = np.percentile(predictions, (1-confidence_level)*100)
    return var_threshold

def backtest_var(y_true, var, confidence_level=0.95):
    violations = np.sum(y_true < var)
    expected_violations = len(y_true) * (1 - confidence_level)
    print(f"Observed Violations: {violations}, Expected Violations: {expected_violations:.2f}")

# Main workflow
if __name__ == "__main__":
    # Example file path (update as necessary)
    file_path = "data/example_data.csv"
    data = load_data(file_path)

    # Preprocess data
    lookback = 30
    X, y = preprocess_data(data['Return'].values, lookback)

    # Train/test split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

    # Build and train model
    model = build_lstm((lookback, 1))
    model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)

    # Make predictions
    predictions = model.predict(X_test)

    # Evaluate
    evaluate_model(y_test, predictions, data['Date'][-len(y_test):])

    # Calculate VaR
    var_threshold = calculate_var(predictions)
    print(f"Value at Risk (VaR) Threshold: {var_threshold:.4f}")

    # Backtest VaR
    backtest_var(y_test, var_threshold)






# Projet de Prédiction de la Value at Risk (VaR) - Livrable de la phase 2

## 1. Versions avancées des algorithmes
- Le modèle LSTM a été implémenté pour prédire les rendements futurs à partir des données historiques.

## 2. Plan d'apprentissage et de test
- **Choix des données** : Les rendements historiques extraits des données de prix.
- **Prétraitement des données** :
  - Des séquences de fenêtres de rétrospection (lookback) sont créées pour l'entrée dans le modèle LSTM.
  - Division des données en ensembles d'apprentissage et de test (80/20), garantissant qu'il n'y ait pas de fuite de données.
- **Contrôle de l'overfitting** :
  - Utilisation de l'arrêt précoce (early stopping) et de la validation croisée pendant l'entraînement du modèle.

## 3. Analyse et critique des résultats
- **Métriques** :
  - **MSE** : Mesure de l'exactitude des prédictions.
  - **R²** : Évaluation de l'ajustement du modèle.
  - **Backtesting de la VaR** : Vérification de la capacité du modèle à prédire les pertes extrêmes.
- **Observations** :
  - Un R² élevé pour les marchés stables ; plus faible en période de volatilité élevée.
  - Les violations de la VaR sont conformes aux seuils attendus.

## 4. Apprentissage par ensemble
- Combinaison des prédictions du LSTM avec :
  - VaR basée sur les quantiles historiques pour plus de robustesse.
  - Simulations de Monte Carlo pour tenir compte des risques extrêmes.

---

## Conclusion
- Le modèle LSTM capture efficacement les relations non linéaires et surpasse souvent les méthodes traditionnelles.
- **Limites** :
  - Nécessite une grande quantité de données et de puissance de calcul.
  - Sensible au réglage des hyperparamètres et aux changements de régime du marché.
- **Travaux futurs** :
  - Exploration de modèles hybrides pour améliorer encore les performances.
